# ai-tooling

An easy to use implementation of a fast tokenizer

For use with OpenAI models

## main features
* Returns number of tokens used when given text input
* Estimates number of tokens to be used in the AI's response
* Compatible with ALL available OpenAI models

Important Note: Tiktoken does not include special tokens such as [CLS] or [SEP] in its final count

### installation of ###
using python:
```python
pip install ###
```

### function
This is what makes the tokenizer usable
```python
import ###


```

### usage
Now, just call the function!
```python
###
```
